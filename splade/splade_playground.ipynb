{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (4.40.1)\n",
      "Requirement already satisfied: torch in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SparseEncoder:\n",
    "    def __init__(self, model_id=\"naver/splade_v2_max\"):\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self._model = AutoModelForMaskedLM.from_pretrained(model_id)\n",
    "        # model.evalによって、モデルを評価モードに変更する\n",
    "        self._model.eval()\n",
    "        # extract the ID position to text token mappings\n",
    "        self._idx2token = {idx: token for token, idx in self._tokenizer.get_vocab().items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        # return_tensors='pt'とは、PyTorchテンソルを返すことを指定する\n",
    "        tokens = self._tokenizer([text], return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            output = self._model(**tokens)\n",
    "\n",
    "        # output.logitsとは、モデルの出力であり、各トークンのスコアを表す\n",
    "        logits = output.logits\n",
    "        relu_logits = torch.relu(logits)\n",
    "        log_relu_logits = torch.log(1 + relu_logits)\n",
    "        attention_mask = tokens.attention_mask\n",
    "        attention_mask_unsqueezed = attention_mask.unsqueeze(-1)\n",
    "        logits_x_attention_mask = log_relu_logits * attention_mask_unsqueezed\n",
    "\n",
    "        # torch.maxをdim=1で適用することで、各トークンの最大スコアを取得する\n",
    "        max_scores_by_tokens = torch.max(logits_x_attention_mask, dim=1).values\n",
    "        print('logits', logits.shape, logits)\n",
    "        print('relu_logits', relu_logits.shape, relu_logits)\n",
    "        print('log_relu_logits', log_relu_logits.shape, log_relu_logits)\n",
    "        print('attention_mask', attention_mask.shape, attention_mask)\n",
    "        print('attention_mask_unsqueezed', attention_mask_unsqueezed.shape)\n",
    "        print('logits_x_attention_mask', logits_x_attention_mask.shape)\n",
    "        print('max_scores_by_tokens', max_scores_by_tokens.shape)\n",
    "\n",
    "        vec = max_scores_by_tokens.squeeze() # squeeze()は次元数が1の次元を削除する\n",
    "        print('max_scores_by_tokens_squeezed', vec.shape)\n",
    "\n",
    "        # nonzeros()で非ゼロの値のインデックスを返す\n",
    "        nonzero_max_values = vec.nonzero()\n",
    "        print('max_scores_by_tokens', nonzero_max_values.shape, nonzero_max_values[0])\n",
    "        cols = nonzero_max_values.squeeze().cpu().tolist()\n",
    "        print('cols', cols)\n",
    "        # 非ゼロ要素のインデックスで重みを取得する\n",
    "        weights = vec[cols].cpu().tolist()\n",
    "        print('weights', weights)\n",
    "        # use to create a dictionary of token ID to weight\n",
    "        sparse_dict = dict(zip(cols, weights))\n",
    "        # map token IDs to human-readable tokens\n",
    "        sparse_dict_tokens = {\n",
    "            self._idx2token[idx]: round(weight, 4) for idx, weight in zip(cols, weights)\n",
    "        }\n",
    "        # sort so we can see most relevant tokens first\n",
    "        # .items()でキーと値のペアを取得する\n",
    "        dict_items = sparse_dict_tokens.items()\n",
    "        print('dict_items', dict_items)\n",
    "        sorted_sparse_dict_tokens = sorted(\n",
    "                dict_items,\n",
    "                key=lambda item: item[1],\n",
    "                reverse=True\n",
    "            )\n",
    "        print('sorted_sparse_dict_tokens', sorted_sparse_dict_tokens)\n",
    "\n",
    "        sparse_dict_tokens = {\n",
    "            k: v for k, v in sorted_sparse_dict_tokens\n",
    "        }\n",
    "        return sparse_dict_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([1, 18, 30522]) tensor([[[ -7.4206,  -7.4528,  -7.6990,  ...,  -6.3517,  -6.4922,  -7.4430],\n",
      "         [-14.1387, -14.2438, -14.4285,  ..., -12.6452, -12.2198, -17.7459],\n",
      "         [-13.4026, -13.4891, -13.8986,  ..., -11.5533, -11.8254, -13.5814],\n",
      "         ...,\n",
      "         [ -6.9746,  -7.0242,  -7.3337,  ...,  -6.0591,  -5.8105,  -8.1359],\n",
      "         [ -8.2372,  -8.3405,  -8.6611,  ...,  -7.1867,  -7.2440,  -9.9187],\n",
      "         [ -8.9823,  -9.0616,  -9.2012,  ...,  -7.4842,  -7.4102,  -8.1561]]])\n",
      "relu_logits torch.Size([1, 18, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "log_relu_logits torch.Size([1, 18, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "attention_mask torch.Size([1, 18]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "attention_mask_unsqueezed torch.Size([1, 18, 1])\n",
      "logits_x_attention_mask torch.Size([1, 18, 30522])\n",
      "max_scores_by_tokens torch.Size([1, 30522])\n",
      "max_scores_by_tokens_squeezed torch.Size([30522])\n",
      "max_scores_by_tokens torch.Size([36, 1]) tensor([2003])\n",
      "cols [2003, 2094, 2203, 2275, 2306, 2331, 2557, 2765, 2832, 3040, 3102, 3125, 3274, 3280, 3426, 3526, 3571, 3574, 3642, 4148, 4340, 4442, 4651, 4758, 4962, 6531, 7473, 7816, 8080, 10327, 11767, 12222, 15176, 15923, 16984, 22851]\n",
      "weights [0.3682198226451874, 1.9653159379959106, 0.32817405462265015, 1.1261744499206543, 0.5619083046913147, 2.406843662261963, 0.49518799781799316, 0.33764004707336426, 0.18180310726165771, 0.49542859196662903, 0.6576936841011047, 0.42090341448783875, 1.2483779191970825, 1.4700709581375122, 0.10960039496421814, 2.066164970397949, 0.14875401556491852, 1.4017256498336792, 0.6976702213287354, 0.016282785683870316, 0.2550234794616699, 0.7753739356994629, 0.23275695741176605, 0.5732572674751282, 0.11202836036682129, 0.1534031331539154, 2.5904500484466553, 1.2420343160629272, 0.23541158437728882, 0.4649326801300049, 0.6679333448410034, 1.4701987504959106, 0.8089574575424194, 1.6084015369415283, 2.06242299079895, 0.08342502266168594]\n",
      "dict_items dict_items([('is', 0.3682), ('##d', 1.9653), ('end', 0.3282), ('set', 1.1262), ('within', 0.5619), ('death', 2.4068), ('radio', 0.4952), ('result', 0.3376), ('process', 0.1818), ('master', 0.4954), ('kill', 0.6577), ('goal', 0.4209), ('computer', 1.2484), ('die', 1.4701), ('cause', 0.1096), ('cell', 2.0662), ('fear', 0.1488), ('meaning', 1.4017), ('code', 0.6977), ('happen', 0.0163), ('determined', 0.255), ('cells', 0.7754), ('transfer', 0.2328), ('controlled', 0.5733), ('gene', 0.112), ('penalty', 0.1534), ('pc', 2.5905), ('regulation', 1.242), ('monitor', 0.2354), ('bacteria', 0.4649), ('organisms', 0.6679), ('regulated', 1.4702), ('regulate', 0.809), ('organism', 1.6084), ('programmed', 2.0624), ('pd', 0.0834)])\n",
      "sorted_sparse_dict_tokens [('pc', 2.5905), ('death', 2.4068), ('cell', 2.0662), ('programmed', 2.0624), ('##d', 1.9653), ('organism', 1.6084), ('regulated', 1.4702), ('die', 1.4701), ('meaning', 1.4017), ('computer', 1.2484), ('regulation', 1.242), ('set', 1.1262), ('regulate', 0.809), ('cells', 0.7754), ('code', 0.6977), ('organisms', 0.6679), ('kill', 0.6577), ('controlled', 0.5733), ('within', 0.5619), ('master', 0.4954), ('radio', 0.4952), ('bacteria', 0.4649), ('goal', 0.4209), ('is', 0.3682), ('result', 0.3376), ('end', 0.3282), ('determined', 0.255), ('monitor', 0.2354), ('transfer', 0.2328), ('process', 0.1818), ('penalty', 0.1534), ('fear', 0.1488), ('gene', 0.112), ('cause', 0.1096), ('pd', 0.0834), ('happen', 0.0163)]\n"
     ]
    }
   ],
   "source": [
    "sparce_encoder = SparseEncoder()\n",
    "text =  \"Programmed cell death (PCD) is the regulated death of cells within an organism\"\n",
    "sparce_vector = sparce_encoder.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pc': 2.5905,\n",
       " 'death': 2.4068,\n",
       " 'cell': 2.0662,\n",
       " 'programmed': 2.0624,\n",
       " '##d': 1.9653,\n",
       " 'organism': 1.6084,\n",
       " 'regulated': 1.4702,\n",
       " 'die': 1.4701,\n",
       " 'meaning': 1.4017,\n",
       " 'computer': 1.2484,\n",
       " 'regulation': 1.242,\n",
       " 'set': 1.1262,\n",
       " 'regulate': 0.809,\n",
       " 'cells': 0.7754,\n",
       " 'code': 0.6977,\n",
       " 'organisms': 0.6679,\n",
       " 'kill': 0.6577,\n",
       " 'controlled': 0.5733,\n",
       " 'within': 0.5619,\n",
       " 'master': 0.4954,\n",
       " 'radio': 0.4952,\n",
       " 'bacteria': 0.4649,\n",
       " 'goal': 0.4209,\n",
       " 'is': 0.3682,\n",
       " 'result': 0.3376,\n",
       " 'end': 0.3282,\n",
       " 'determined': 0.255,\n",
       " 'monitor': 0.2354,\n",
       " 'transfer': 0.2328,\n",
       " 'process': 0.1818,\n",
       " 'penalty': 0.1534,\n",
       " 'fear': 0.1488,\n",
       " 'gene': 0.112,\n",
       " 'cause': 0.1096,\n",
       " 'pd': 0.0834,\n",
       " 'happen': 0.0163}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparce_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([1, 13, 30522]) tensor([[[ -8.0085,  -7.9910,  -8.0943,  ...,  -7.2088,  -6.7127,  -7.7589],\n",
      "         [-12.4164, -12.5163, -12.4281,  ..., -10.3584,  -9.8625, -12.4319],\n",
      "         [-13.6496, -13.4941, -13.7159,  ..., -11.5093, -11.0709, -12.6855],\n",
      "         ...,\n",
      "         [-10.0733, -10.0550, -10.2393,  ...,  -8.6230,  -8.7384,  -8.4065],\n",
      "         [-10.4967, -10.5393, -10.5337,  ...,  -8.2109,  -8.5428,  -9.7887],\n",
      "         [-10.1714, -10.2071, -10.2485,  ...,  -8.2812,  -8.2802,  -9.3571]]])\n",
      "relu_logits torch.Size([1, 13, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "log_relu_logits torch.Size([1, 13, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "attention_mask torch.Size([1, 13]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "attention_mask_unsqueezed torch.Size([1, 13, 1])\n",
      "logits_x_attention_mask torch.Size([1, 13, 30522])\n",
      "max_scores_by_tokens torch.Size([1, 30522])\n",
      "max_scores_by_tokens_squeezed torch.Size([30522])\n",
      "max_scores_by_tokens torch.Size([56, 1]) tensor([2009])\n",
      "cols [2009, 2120, 2373, 2597, 2646, 2689, 2693, 2735, 2783, 2812, 2875, 2897, 2928, 2929, 2943, 3006, 3068, 3120, 3125, 3257, 3343, 3579, 3617, 3623, 3751, 3795, 4132, 4139, 4216, 4353, 4522, 4742, 4753, 4792, 4969, 5670, 5684, 5769, 6089, 6454, 6592, 6622, 6689, 7325, 7461, 7731, 8339, 8361, 9084, 9874, 12363, 12878, 13918, 15169, 16216, 20248]\n",
      "weights [0.2871631383895874, 0.18597939610481262, 0.966913104057312, 0.09399651736021042, 1.4509333372116089, 0.7915962338447571, 0.9542606472969055, 0.19180232286453247, 0.5051183104515076, 0.32656511664390564, 1.4805269241333008, 0.6067102551460266, 0.05342545732855797, 0.8496479392051697, 1.7373011112213135, 2.208204984664917, 0.5598012208938599, 1.0791881084442139, 0.2009558379650116, 0.46830734610557556, 0.7389610409736633, 0.5818284153938293, 0.23424126207828522, 0.4508795142173767, 0.3907291293144226, 2.3839011192321777, 0.6346433758735657, 0.3712391257286072, 0.3508685529232025, 0.5819859504699707, 1.172455906867981, 0.743444561958313, 0.7582272887229919, 0.1474040299654007, 1.3056483268737793, 1.8731895685195923, 0.844572901725769, 1.4702894687652588, 1.0402315855026245, 0.2938479483127594, 0.030744493007659912, 0.30236464738845825, 0.44008857011795044, 0.3297556936740875, 0.23726747930049896, 0.2227374017238617, 0.2882876396179199, 0.509888231754303, 1.158608078956604, 1.8940123319625854, 0.9642331004142761, 1.4855300188064575, 2.0742030143737793, 0.1637721210718155, 0.1587466150522232, 1.2086139917373657]\n",
      "dict_items dict_items([('it', 0.2872), ('national', 0.186), ('power', 0.9669), ('position', 0.094), ('toward', 1.4509), ('change', 0.7916), ('move', 0.9543), ('turn', 0.1918), ('current', 0.5051), ('mean', 0.3266), ('towards', 1.4805), ('network', 0.6067), ('mark', 0.0534), ('movement', 0.8496), ('energy', 1.7373), ('market', 2.2082), ('industry', 0.5598), ('source', 1.0792), ('goal', 0.201), ('direction', 0.4683), ('policy', 0.739), ('focus', 0.5818), ('digital', 0.2342), ('increase', 0.4509), ('electric', 0.3907), ('global', 2.3839), ('platform', 0.6346), ('pull', 0.3712), ('sources', 0.3509), ('distribution', 0.582), ('alternative', 1.1725), ('signal', 0.7434), ('sector', 0.7582), ('desire', 0.1474), ('worldwide', 1.3056), ('shift', 1.8732), ('favor', 0.8446), ('indicate', 1.4703), ('markets', 1.0402), ('symbol', 0.2938), ('suggest', 0.0307), ('evolution', 0.3024), ('decline', 0.4401), ('consumer', 0.3298), ('affect', 0.2373), ('mainstream', 0.2227), ('reflect', 0.2883), ('emerging', 0.5099), ('sustainable', 1.1586), ('trend', 1.894), ('shifts', 0.9642), ('trends', 1.4855), ('renewable', 2.0742), ('sustainability', 0.1638), ('ge', 0.1587), ('geo', 1.2086)])\n",
      "sorted_sparse_dict_tokens [('global', 2.3839), ('market', 2.2082), ('renewable', 2.0742), ('trend', 1.894), ('shift', 1.8732), ('energy', 1.7373), ('trends', 1.4855), ('towards', 1.4805), ('indicate', 1.4703), ('toward', 1.4509), ('worldwide', 1.3056), ('geo', 1.2086), ('alternative', 1.1725), ('sustainable', 1.1586), ('source', 1.0792), ('markets', 1.0402), ('power', 0.9669), ('shifts', 0.9642), ('move', 0.9543), ('movement', 0.8496), ('favor', 0.8446), ('change', 0.7916), ('sector', 0.7582), ('signal', 0.7434), ('policy', 0.739), ('platform', 0.6346), ('network', 0.6067), ('distribution', 0.582), ('focus', 0.5818), ('industry', 0.5598), ('emerging', 0.5099), ('current', 0.5051), ('direction', 0.4683), ('increase', 0.4509), ('decline', 0.4401), ('electric', 0.3907), ('pull', 0.3712), ('sources', 0.3509), ('consumer', 0.3298), ('mean', 0.3266), ('evolution', 0.3024), ('symbol', 0.2938), ('reflect', 0.2883), ('it', 0.2872), ('affect', 0.2373), ('digital', 0.2342), ('mainstream', 0.2227), ('goal', 0.201), ('turn', 0.1918), ('national', 0.186), ('sustainability', 0.1638), ('ge', 0.1587), ('desire', 0.1474), ('position', 0.094), ('mark', 0.0534), ('suggest', 0.0307)]\n",
      "logits torch.Size([1, 10, 30522]) tensor([[[ -7.7653,  -7.7301,  -7.8940,  ...,  -6.8964,  -6.4685,  -7.8523],\n",
      "         [-10.8643, -10.7872, -10.9486,  ...,  -8.6215,  -9.2660, -10.4452],\n",
      "         [ -9.3156,  -9.1836,  -9.6082,  ...,  -7.8739,  -8.4007,  -9.2083],\n",
      "         ...,\n",
      "         [-10.3553, -10.2679, -10.4668,  ...,  -9.1008,  -8.5139,  -9.4775],\n",
      "         [-10.0434, -10.0747, -10.1225,  ...,  -7.8354,  -8.0570,  -9.5468],\n",
      "         [ -9.8482,  -9.8548,  -9.9790,  ...,  -7.9508,  -7.9365,  -9.2937]]])\n",
      "relu_logits torch.Size([1, 10, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "log_relu_logits torch.Size([1, 10, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "attention_mask torch.Size([1, 10]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "attention_mask_unsqueezed torch.Size([1, 10, 1])\n",
      "logits_x_attention_mask torch.Size([1, 10, 30522])\n",
      "max_scores_by_tokens torch.Size([1, 30522])\n",
      "max_scores_by_tokens_squeezed torch.Size([30522])\n",
      "max_scores_by_tokens torch.Size([50, 1]) tensor([2009])\n",
      "cols [2009, 2449, 2689, 2729, 2740, 2801, 2902, 2966, 2974, 3068, 3239, 3430, 3452, 3751, 3795, 4007, 4044, 4118, 4132, 4200, 4432, 4495, 4522, 4753, 4784, 4975, 5080, 5278, 5427, 5656, 6028, 6047, 6349, 6377, 6612, 6786, 7782, 7965, 8144, 8323, 8361, 8651, 9525, 9871, 10660, 10938, 16216, 16771, 17903, 20300]\n",
      "weights [0.33921927213668823, 0.9889424443244934, 0.2906331717967987, 1.097887396812439, 1.647801399230957, 1.0572211742401123, 1.4104952812194824, 0.41199997067451477, 1.851691484451294, 1.9234710931777954, 0.5793739557266235, 0.10344900190830231, 0.1902240663766861, 0.502598762512207, 0.06400366127490997, 0.4306299686431885, 0.35990580916404724, 0.9153637290000916, 0.41377899050712585, 1.24256432056427, 0.2434357851743698, 0.03524402901530266, 0.7270200848579407, 1.0653760433197021, 0.05160709470510483, 0.5982896685600281, 0.13603617250919342, 0.3788703382015228, 0.5939455628395081, 0.6032922863960266, 0.13412737846374512, 1.0334843397140503, 0.650862991809845, 0.7980541586875916, 0.29898208379745483, 1.6299777030944824, 0.9195477366447449, 0.42234867811203003, 1.263900876045227, 0.20689943432807922, 1.1408315896987915, 0.7964463233947754, 1.7896478176116943, 1.6466257572174072, 1.0296248197555542, 0.8928433060646057, 0.11163458973169327, 0.0011176775442436337, 0.8499088883399963, 0.2814773619174957]\n",
      "dict_items dict_items([('it', 0.3392), ('business', 0.9889), ('change', 0.2906), ('care', 1.0979), ('health', 1.6478), ('idea', 1.0572), ('hospital', 1.4105), ('medical', 0.412), ('technology', 1.8517), ('industry', 1.9235), ('eye', 0.5794), ('material', 0.1034), ('overall', 0.1902), ('electric', 0.5026), ('global', 0.064), ('software', 0.4306), ('environment', 0.3599), ('method', 0.9154), ('platform', 0.4138), ('medicine', 1.2426), ('vision', 0.2434), ('opportunity', 0.0352), ('alternative', 0.727), ('sector', 1.0654), ('ideas', 0.0516), ('developing', 0.5983), ('device', 0.136), ('changing', 0.3789), ('insurance', 0.5939), ('strategy', 0.6033), ('technique', 0.1341), ('smart', 1.0335), ('initiative', 0.6509), ('integrated', 0.7981), ('clinical', 0.299), ('technologies', 1.63), ('bold', 0.9195), ('healthy', 0.4223), ('innovation', 1.2639), ('hospitals', 0.2069), ('emerging', 1.1408), ('transformation', 0.7964), ('innovative', 1.7896), ('healthcare', 1.6466), ('technological', 1.0296), ('transform', 0.8928), ('ge', 0.1116), ('catalyst', 0.0011), ('transforming', 0.8499), ('shaping', 0.2815)])\n",
      "sorted_sparse_dict_tokens [('industry', 1.9235), ('technology', 1.8517), ('innovative', 1.7896), ('health', 1.6478), ('healthcare', 1.6466), ('technologies', 1.63), ('hospital', 1.4105), ('innovation', 1.2639), ('medicine', 1.2426), ('emerging', 1.1408), ('care', 1.0979), ('sector', 1.0654), ('idea', 1.0572), ('smart', 1.0335), ('technological', 1.0296), ('business', 0.9889), ('bold', 0.9195), ('method', 0.9154), ('transform', 0.8928), ('transforming', 0.8499), ('integrated', 0.7981), ('transformation', 0.7964), ('alternative', 0.727), ('initiative', 0.6509), ('strategy', 0.6033), ('developing', 0.5983), ('insurance', 0.5939), ('eye', 0.5794), ('electric', 0.5026), ('software', 0.4306), ('healthy', 0.4223), ('platform', 0.4138), ('medical', 0.412), ('changing', 0.3789), ('environment', 0.3599), ('it', 0.3392), ('clinical', 0.299), ('change', 0.2906), ('shaping', 0.2815), ('vision', 0.2434), ('hospitals', 0.2069), ('overall', 0.1902), ('device', 0.136), ('technique', 0.1341), ('ge', 0.1116), ('material', 0.1034), ('global', 0.064), ('ideas', 0.0516), ('opportunity', 0.0352), ('catalyst', 0.0011)]\n",
      "logits torch.Size([1, 11, 30522]) tensor([[[ -7.6975,  -7.7809,  -7.8860,  ...,  -6.8614,  -6.5401,  -6.9977],\n",
      "         [-11.8610, -12.0254, -12.2126,  ..., -10.3483, -10.5456, -12.1842],\n",
      "         [-10.8022, -10.8000, -10.9809,  ...,  -8.8343,  -9.5943, -10.3619],\n",
      "         ...,\n",
      "         [ -9.5705,  -9.5278,  -9.6671,  ...,  -7.7293,  -8.4212,  -8.8114],\n",
      "         [-10.6045, -10.6647, -10.6273,  ...,  -8.3688,  -8.5454,  -9.8442],\n",
      "         [-10.4593, -10.5337, -10.5279,  ...,  -8.4867,  -8.4696,  -9.6336]]])\n",
      "relu_logits torch.Size([1, 11, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "log_relu_logits torch.Size([1, 11, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "attention_mask torch.Size([1, 11]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "attention_mask_unsqueezed torch.Size([1, 11, 1])\n",
      "logits_x_attention_mask torch.Size([1, 11, 30522])\n",
      "max_scores_by_tokens torch.Size([1, 30522])\n",
      "max_scores_by_tokens_squeezed torch.Size([30522])\n",
      "max_scores_by_tokens torch.Size([48, 1]) tensor([2005])\n",
      "cols [2005, 2009, 2030, 2082, 2291, 2323, 2342, 2393, 2430, 2458, 2495, 2590, 2627, 2689, 2731, 2734, 2775, 2783, 2801, 2925, 3095, 3105, 3125, 3223, 3431, 3537, 4022, 4072, 4450, 4503, 4547, 4826, 4975, 5009, 5082, 5161, 5197, 5239, 5290, 6827, 6912, 7450, 8818, 8995, 11405, 13921, 14877, 24767]\n",
      "weights [0.5696698427200317, 0.3310117721557617, 0.09287504106760025, 1.2157280445098877, 0.04099062830209732, 0.08199063688516617, 1.251106858253479, 0.603236734867096, 0.016099806874990463, 1.6155924797058105, 1.9200561046600342, 1.121986746788025, 0.11712764948606491, 1.3922024965286255, 0.9835730195045471, 0.04674534872174263, 0.4443059265613556, 0.39168909192085266, 0.7000632286071777, 1.8785628080368042, 0.7637757658958435, 1.3112696409225464, 0.20897340774536133, 0.5285954475402832, 0.6872884035110474, 0.07129786908626556, 0.05538681149482727, 0.8744876980781555, 0.5408019423484802, 0.2887711226940155, 1.6407597064971924, 0.05019693449139595, 0.22198015451431274, 0.26809486746788025, 0.5133208632469177, 0.6437937021255493, 0.7989123463630676, 0.041230082511901855, 2.155329465866089, 1.7515698671340942, 0.11401358991861343, 0.2983514070510864, 1.8660345077514648, 0.65206378698349, 0.27212679386138916, 0.25812238454818726, 2.093966484069824, 0.3731147348880768]\n",
      "dict_items dict_items([('for', 0.5697), ('it', 0.331), ('or', 0.0929), ('school', 1.2157), ('system', 0.041), ('should', 0.082), ('need', 1.2511), ('help', 0.6032), ('central', 0.0161), ('development', 1.6156), ('education', 1.9201), ('important', 1.122), ('past', 0.1171), ('change', 1.3922), ('training', 0.9836), ('needed', 0.0467), ('child', 0.4443), ('current', 0.3917), ('idea', 0.7001), ('future', 1.8786), ('staff', 0.7638), ('job', 1.3113), ('goal', 0.209), ('required', 0.5286), ('changes', 0.6873), ('democratic', 0.0713), ('potential', 0.0554), ('necessary', 0.8745), ('labor', 0.5408), ('develop', 0.2888), ('educational', 1.6408), ('tomorrow', 0.0502), ('developing', 0.222), ('guide', 0.2681), ('progress', 0.5133), ('educated', 0.6438), ('importance', 0.7989), ('cabinet', 0.0412), ('reform', 2.1553), ('essential', 1.7516), ('exercise', 0.114), ('amendment', 0.2984), ('reforms', 1.866), ('vital', 0.6521), ('mandate', 0.2721), ('revision', 0.2581), ('workforce', 2.094), ('reformer', 0.3731)])\n",
      "sorted_sparse_dict_tokens [('reform', 2.1553), ('workforce', 2.094), ('education', 1.9201), ('future', 1.8786), ('reforms', 1.866), ('essential', 1.7516), ('educational', 1.6408), ('development', 1.6156), ('change', 1.3922), ('job', 1.3113), ('need', 1.2511), ('school', 1.2157), ('important', 1.122), ('training', 0.9836), ('necessary', 0.8745), ('importance', 0.7989), ('staff', 0.7638), ('idea', 0.7001), ('changes', 0.6873), ('vital', 0.6521), ('educated', 0.6438), ('help', 0.6032), ('for', 0.5697), ('labor', 0.5408), ('required', 0.5286), ('progress', 0.5133), ('child', 0.4443), ('current', 0.3917), ('reformer', 0.3731), ('it', 0.331), ('amendment', 0.2984), ('develop', 0.2888), ('mandate', 0.2721), ('guide', 0.2681), ('revision', 0.2581), ('developing', 0.222), ('goal', 0.209), ('past', 0.1171), ('exercise', 0.114), ('or', 0.0929), ('should', 0.082), ('democratic', 0.0713), ('potential', 0.0554), ('tomorrow', 0.0502), ('needed', 0.0467), ('cabinet', 0.0412), ('system', 0.041), ('central', 0.0161)]\n",
      "logits torch.Size([1, 12, 30522]) tensor([[[ -7.7908,  -7.8471,  -8.0378,  ...,  -7.1844,  -6.7150,  -7.3950],\n",
      "         [-11.8492, -12.0653, -12.2116,  ..., -11.0337, -10.2642, -12.6309],\n",
      "         [-12.0767, -12.1121, -12.4737,  ..., -10.5648, -10.4272, -12.2117],\n",
      "         ...,\n",
      "         [-11.1990, -11.1643, -11.3299,  ...,  -8.9946,  -9.7397, -11.4794],\n",
      "         [-10.8315, -10.8728, -10.8875,  ...,  -8.5379,  -8.8939, -10.1488],\n",
      "         [-10.6153, -10.6842, -10.7206,  ...,  -8.7577,  -8.7318,  -9.7992]]])\n",
      "relu_logits torch.Size([1, 12, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "log_relu_logits torch.Size([1, 12, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "attention_mask torch.Size([1, 12]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "attention_mask_unsqueezed torch.Size([1, 12, 1])\n",
      "logits_x_attention_mask torch.Size([1, 12, 30522])\n",
      "max_scores_by_tokens torch.Size([1, 30522])\n",
      "max_scores_by_tokens_squeezed torch.Size([30522])\n",
      "max_scores_by_tokens torch.Size([45, 1]) tensor([2000])\n",
      "cols [2000, 2057, 2114, 2147, 2342, 2393, 2491, 2590, 2689, 2740, 2801, 2954, 3125, 3147, 3431, 3445, 3554, 3623, 3652, 3795, 3860, 3947, 4044, 4047, 4073, 4111, 4337, 4483, 4633, 4652, 4675, 4785, 4803, 4852, 5197, 5368, 5547, 5680, 6552, 6870, 7552, 8347, 9740, 11768, 12959]\n",
      "weights [0.34061339497566223, 0.13676071166992188, 0.618384838104248, 0.7306272387504578, 0.021932315081357956, 1.25371515750885, 0.5174136161804199, 0.0049257357604801655, 1.7092207670211792, 0.05536448210477829, 0.29408252239227295, 1.2573556900024414, 0.9923951625823975, 0.6917506456375122, 0.4355907440185547, 0.5238920450210571, 1.2021759748458862, 1.6544067859649658, 0.5923423767089844, 0.9186052083969116, 1.2564055919647217, 1.2180378437042236, 1.2165920734405518, 0.1150582805275917, 1.3261184692382812, 0.44398754835128784, 1.456298589706421, 1.9051316976547241, 1.193984031677246, 0.11380445957183838, 0.8616408109664917, 1.994308352470398, 0.46534857153892517, 1.4278745651245117, 0.4689040184020996, 0.08379387110471725, 0.35105299949645996, 2.428938865661621, 0.025808347389101982, 0.7287810444831848, 0.2612777352333069, 1.32049560546875, 0.35167792439460754, 0.11821834743022919, 0.9970885515213013]\n",
      "dict_items dict_items([('to', 0.3406), ('we', 0.1368), ('against', 0.6184), ('work', 0.7306), ('need', 0.0219), ('help', 1.2537), ('control', 0.5174), ('important', 0.0049), ('change', 1.7092), ('health', 0.0554), ('idea', 0.2941), ('fight', 1.2574), ('goal', 0.9924), ('cold', 0.6918), ('changes', 0.4356), ('increased', 0.5239), ('fighting', 1.2022), ('increase', 1.6544), ('growing', 0.5923), ('global', 0.9186), ('protection', 1.2564), ('effort', 1.218), ('environment', 1.2166), ('protect', 0.1151), ('efforts', 1.3261), ('animal', 0.444), ('combat', 1.4563), ('environmental', 1.9051), ('weather', 1.194), ('prevent', 0.1138), ('counter', 0.8616), ('climate', 1.9943), ('rising', 0.4653), ('increasing', 1.4279), ('importance', 0.4689), ('responsibility', 0.0838), ('reduce', 0.3511), ('conservation', 2.4289), ('habitat', 0.0258), ('wildlife', 0.7288), ('ongoing', 0.2613), ('preservation', 1.3205), ('prevention', 0.3517), ('emissions', 0.1182), ('warming', 0.9971)])\n",
      "sorted_sparse_dict_tokens [('conservation', 2.4289), ('climate', 1.9943), ('environmental', 1.9051), ('change', 1.7092), ('increase', 1.6544), ('combat', 1.4563), ('increasing', 1.4279), ('efforts', 1.3261), ('preservation', 1.3205), ('fight', 1.2574), ('protection', 1.2564), ('help', 1.2537), ('effort', 1.218), ('environment', 1.2166), ('fighting', 1.2022), ('weather', 1.194), ('warming', 0.9971), ('goal', 0.9924), ('global', 0.9186), ('counter', 0.8616), ('work', 0.7306), ('wildlife', 0.7288), ('cold', 0.6918), ('against', 0.6184), ('growing', 0.5923), ('increased', 0.5239), ('control', 0.5174), ('importance', 0.4689), ('rising', 0.4653), ('animal', 0.444), ('changes', 0.4356), ('prevention', 0.3517), ('reduce', 0.3511), ('to', 0.3406), ('idea', 0.2941), ('ongoing', 0.2613), ('we', 0.1368), ('emissions', 0.1182), ('protect', 0.1151), ('prevent', 0.1138), ('responsibility', 0.0838), ('health', 0.0554), ('habitat', 0.0258), ('need', 0.0219), ('important', 0.0049)]\n",
      "logits torch.Size([1, 12, 30522]) tensor([[[ -8.0929,  -8.1400,  -8.2824,  ...,  -7.3970,  -6.8974,  -8.4827],\n",
      "         [-13.4400, -13.5553, -13.7110,  ..., -12.0659, -11.6240, -15.3429],\n",
      "         [-12.6514, -12.6423, -12.6701,  ..., -11.6587, -10.8723, -13.7439],\n",
      "         ...,\n",
      "         [ -9.5844,  -9.3729,  -9.7491,  ...,  -8.3823,  -7.9093, -10.4635],\n",
      "         [-10.4862, -10.5754, -10.5489,  ...,  -8.3005,  -8.4866,  -9.9033],\n",
      "         [-10.4259, -10.5354, -10.5363,  ...,  -8.5867,  -8.4280,  -9.8345]]])\n",
      "relu_logits torch.Size([1, 12, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "log_relu_logits torch.Size([1, 12, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "attention_mask torch.Size([1, 12]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "attention_mask_unsqueezed torch.Size([1, 12, 1])\n",
      "logits_x_attention_mask torch.Size([1, 12, 30522])\n",
      "max_scores_by_tokens torch.Size([1, 30522])\n",
      "max_scores_by_tokens_squeezed torch.Size([30522])\n",
      "max_scores_by_tokens torch.Size([45, 1]) tensor([2003])\n",
      "cols [2003, 2008, 2009, 2017, 2030, 2075, 2126, 2129, 2147, 2194, 2339, 2393, 2448, 2449, 2651, 2801, 2974, 3019, 3068, 3105, 3125, 3169, 3291, 3293, 3550, 3571, 3813, 3840, 3989, 4329, 4454, 4610, 5452, 5661, 5748, 5821, 6026, 6208, 6960, 7976, 9926, 11581, 12553, 15293, 26264]\n",
      "weights [0.45116502046585083, 0.03295855596661568, 1.0973339080810547, 0.1156969740986824, 0.23632749915122986, 0.39482417702674866, 1.2862848043441772, 0.827077329158783, 0.08495612442493439, 0.8547074198722839, 1.0050246715545654, 0.49959591031074524, 0.70749831199646, 1.8945974111557007, 0.12792809307575226, 0.6635859608650208, 0.21870121359825134, 1.2140703201293945, 0.9218344688415527, 0.148759663105011, 0.66425621509552, 0.8895317912101746, 0.006912603043019772, 0.8103873133659363, 0.5771854519844055, 0.12936389446258545, 0.298161119222641, 0.13275466859340668, 0.20682062208652496, 2.117166042327881, 2.2052228450775146, 0.319172203540802, 1.2048977613449097, 1.488525390625, 0.687150776386261, 0.4246350824832916, 1.1341904401779175, 0.6891103982925415, 0.6384763717651367, 2.508796453475952, 0.7473887801170349, 0.6949959397315979, 0.3752910792827606, 0.24470899999141693, 0.14807863533496857]\n",
      "dict_items dict_items([('is', 0.4512), ('that', 0.033), ('it', 1.0973), ('you', 0.1157), ('or', 0.2363), ('##ing', 0.3948), ('way', 1.2863), ('how', 0.8271), ('work', 0.085), ('company', 0.8547), ('why', 1.005), ('help', 0.4996), ('run', 0.7075), ('business', 1.8946), ('today', 0.1279), ('idea', 0.6636), ('technology', 0.2187), ('natural', 1.2141), ('industry', 0.9218), ('job', 0.1488), ('goal', 0.6643), ('operation', 0.8895), ('problem', 0.0069), ('commercial', 0.8104), ('##ized', 0.5772), ('fear', 0.1294), ('firm', 0.2982), ('corporation', 0.1328), ('##ization', 0.2068), ('revolution', 2.1172), ('intelligence', 2.2052), ('economy', 0.3192), ('operate', 1.2049), ('businesses', 1.4885), ('operates', 0.6872), ('marketing', 0.4246), ('##izing', 1.1342), ('revolutionary', 0.6891), ('enterprise', 0.6385), ('artificial', 2.5088), ('enterprises', 0.7474), ('rational', 0.695), ('synthetic', 0.3753), ('josie', 0.2447), ('iq', 0.1481)])\n",
      "sorted_sparse_dict_tokens [('artificial', 2.5088), ('intelligence', 2.2052), ('revolution', 2.1172), ('business', 1.8946), ('businesses', 1.4885), ('way', 1.2863), ('natural', 1.2141), ('operate', 1.2049), ('##izing', 1.1342), ('it', 1.0973), ('why', 1.005), ('industry', 0.9218), ('operation', 0.8895), ('company', 0.8547), ('how', 0.8271), ('commercial', 0.8104), ('enterprises', 0.7474), ('run', 0.7075), ('rational', 0.695), ('revolutionary', 0.6891), ('operates', 0.6872), ('goal', 0.6643), ('idea', 0.6636), ('enterprise', 0.6385), ('##ized', 0.5772), ('help', 0.4996), ('is', 0.4512), ('marketing', 0.4246), ('##ing', 0.3948), ('synthetic', 0.3753), ('economy', 0.3192), ('firm', 0.2982), ('josie', 0.2447), ('or', 0.2363), ('technology', 0.2187), ('##ization', 0.2068), ('job', 0.1488), ('iq', 0.1481), ('corporation', 0.1328), ('fear', 0.1294), ('today', 0.1279), ('you', 0.1157), ('work', 0.085), ('that', 0.033), ('problem', 0.0069)]\n"
     ]
    }
   ],
   "source": [
    "# 2つのベクトルのスコア計算（類似単語が多いとスコアが高くなる）\n",
    "def get_score(vec1, vec2):\n",
    "  score = 0.0\n",
    "  for k,v in vec1.items():\n",
    "    if k in vec2:\n",
    "      score += v * vec2.get(k)\n",
    "  return score\n",
    "\n",
    "# 検索対象の文書的なもの\n",
    "texts = [\n",
    "    \"Global market trends indicate a shift towards renewable energy sources.\",\n",
    "    # グローバル市場の動向は、再生可能エネルギー源へのシフトを示しています。\n",
    "    \"Innovative technologies are transforming the healthcare industry.\",\n",
    "    # 革新的な技術がヘルスケア産業を変革しています。\n",
    "    \"Educational reforms are essential for future workforce development.\",\n",
    "    # 教育改革は将来の労働力開発に不可欠です。\n",
    "    \"Environmental conservation efforts are increasing to combat climate change.\",\n",
    "    # 気候変動と戦うために、環境保全の努力が増加しています。\n",
    "    \"Artificial intelligence is revolutionizing the way businesses operate.\"\n",
    "    # 人工知能はビジネスの運営方法を革命的に変えています。\n",
    "]\n",
    "\n",
    "sparce_encoder = SparseEncoder()\n",
    "sparse_vectors = [sparce_encoder.encode(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Global market trends indicate a shift towards renewable energy sources.\n",
      "→ vec: {'global': 2.3839, 'market': 2.2082, 'renewable': 2.0742, 'trend': 1.894, 'shift': 1.8732, 'energy': 1.7373, 'trends': 1.4855, 'towards': 1.4805, 'indicate': 1.4703, 'toward': 1.4509, 'worldwide': 1.3056, 'geo': 1.2086, 'alternative': 1.1725, 'sustainable': 1.1586, 'source': 1.0792, 'markets': 1.0402, 'power': 0.9669, 'shifts': 0.9642, 'move': 0.9543, 'movement': 0.8496, 'favor': 0.8446, 'change': 0.7916, 'sector': 0.7582, 'signal': 0.7434, 'policy': 0.739, 'platform': 0.6346, 'network': 0.6067, 'distribution': 0.582, 'focus': 0.5818, 'industry': 0.5598, 'emerging': 0.5099, 'current': 0.5051, 'direction': 0.4683, 'increase': 0.4509, 'decline': 0.4401, 'electric': 0.3907, 'pull': 0.3712, 'sources': 0.3509, 'consumer': 0.3298, 'mean': 0.3266, 'evolution': 0.3024, 'symbol': 0.2938, 'reflect': 0.2883, 'it': 0.2872, 'affect': 0.2373, 'digital': 0.2342, 'mainstream': 0.2227, 'goal': 0.201, 'turn': 0.1918, 'national': 0.186, 'sustainability': 0.1638, 'ge': 0.1587, 'desire': 0.1474, 'position': 0.094, 'mark': 0.0534, 'suggest': 0.0307}\n",
      "text: Innovative technologies are transforming the healthcare industry.\n",
      "→ vec: {'industry': 1.9235, 'technology': 1.8517, 'innovative': 1.7896, 'health': 1.6478, 'healthcare': 1.6466, 'technologies': 1.63, 'hospital': 1.4105, 'innovation': 1.2639, 'medicine': 1.2426, 'emerging': 1.1408, 'care': 1.0979, 'sector': 1.0654, 'idea': 1.0572, 'smart': 1.0335, 'technological': 1.0296, 'business': 0.9889, 'bold': 0.9195, 'method': 0.9154, 'transform': 0.8928, 'transforming': 0.8499, 'integrated': 0.7981, 'transformation': 0.7964, 'alternative': 0.727, 'initiative': 0.6509, 'strategy': 0.6033, 'developing': 0.5983, 'insurance': 0.5939, 'eye': 0.5794, 'electric': 0.5026, 'software': 0.4306, 'healthy': 0.4223, 'platform': 0.4138, 'medical': 0.412, 'changing': 0.3789, 'environment': 0.3599, 'it': 0.3392, 'clinical': 0.299, 'change': 0.2906, 'shaping': 0.2815, 'vision': 0.2434, 'hospitals': 0.2069, 'overall': 0.1902, 'device': 0.136, 'technique': 0.1341, 'ge': 0.1116, 'material': 0.1034, 'global': 0.064, 'ideas': 0.0516, 'opportunity': 0.0352, 'catalyst': 0.0011}\n",
      "text: Educational reforms are essential for future workforce development.\n",
      "→ vec: {'reform': 2.1553, 'workforce': 2.094, 'education': 1.9201, 'future': 1.8786, 'reforms': 1.866, 'essential': 1.7516, 'educational': 1.6408, 'development': 1.6156, 'change': 1.3922, 'job': 1.3113, 'need': 1.2511, 'school': 1.2157, 'important': 1.122, 'training': 0.9836, 'necessary': 0.8745, 'importance': 0.7989, 'staff': 0.7638, 'idea': 0.7001, 'changes': 0.6873, 'vital': 0.6521, 'educated': 0.6438, 'help': 0.6032, 'for': 0.5697, 'labor': 0.5408, 'required': 0.5286, 'progress': 0.5133, 'child': 0.4443, 'current': 0.3917, 'reformer': 0.3731, 'it': 0.331, 'amendment': 0.2984, 'develop': 0.2888, 'mandate': 0.2721, 'guide': 0.2681, 'revision': 0.2581, 'developing': 0.222, 'goal': 0.209, 'past': 0.1171, 'exercise': 0.114, 'or': 0.0929, 'should': 0.082, 'democratic': 0.0713, 'potential': 0.0554, 'tomorrow': 0.0502, 'needed': 0.0467, 'cabinet': 0.0412, 'system': 0.041, 'central': 0.0161}\n",
      "text: Environmental conservation efforts are increasing to combat climate change.\n",
      "→ vec: {'conservation': 2.4289, 'climate': 1.9943, 'environmental': 1.9051, 'change': 1.7092, 'increase': 1.6544, 'combat': 1.4563, 'increasing': 1.4279, 'efforts': 1.3261, 'preservation': 1.3205, 'fight': 1.2574, 'protection': 1.2564, 'help': 1.2537, 'effort': 1.218, 'environment': 1.2166, 'fighting': 1.2022, 'weather': 1.194, 'warming': 0.9971, 'goal': 0.9924, 'global': 0.9186, 'counter': 0.8616, 'work': 0.7306, 'wildlife': 0.7288, 'cold': 0.6918, 'against': 0.6184, 'growing': 0.5923, 'increased': 0.5239, 'control': 0.5174, 'importance': 0.4689, 'rising': 0.4653, 'animal': 0.444, 'changes': 0.4356, 'prevention': 0.3517, 'reduce': 0.3511, 'to': 0.3406, 'idea': 0.2941, 'ongoing': 0.2613, 'we': 0.1368, 'emissions': 0.1182, 'protect': 0.1151, 'prevent': 0.1138, 'responsibility': 0.0838, 'health': 0.0554, 'habitat': 0.0258, 'need': 0.0219, 'important': 0.0049}\n",
      "text: Artificial intelligence is revolutionizing the way businesses operate.\n",
      "→ vec: {'artificial': 2.5088, 'intelligence': 2.2052, 'revolution': 2.1172, 'business': 1.8946, 'businesses': 1.4885, 'way': 1.2863, 'natural': 1.2141, 'operate': 1.2049, '##izing': 1.1342, 'it': 1.0973, 'why': 1.005, 'industry': 0.9218, 'operation': 0.8895, 'company': 0.8547, 'how': 0.8271, 'commercial': 0.8104, 'enterprises': 0.7474, 'run': 0.7075, 'rational': 0.695, 'revolutionary': 0.6891, 'operates': 0.6872, 'goal': 0.6643, 'idea': 0.6636, 'enterprise': 0.6385, '##ized': 0.5772, 'help': 0.4996, 'is': 0.4512, 'marketing': 0.4246, '##ing': 0.3948, 'synthetic': 0.3753, 'economy': 0.3192, 'firm': 0.2982, 'josie': 0.2447, 'or': 0.2363, 'technology': 0.2187, '##ization': 0.2068, 'job': 0.1488, 'iq': 0.1481, 'corporation': 0.1328, 'fear': 0.1294, 'today': 0.1279, 'you': 0.1157, 'work': 0.085, 'that': 0.033, 'problem': 0.0069}\n"
     ]
    }
   ],
   "source": [
    "# enumerate()はインデックスと要素を同時に取得する\n",
    "for index, vec in enumerate(sparse_vectors):\n",
    "    print(f\"text: {texts[index]}\")\n",
    "    print(f\"→ vec: {vec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([1, 4, 30522]) tensor([[[ -9.3298,  -9.3722,  -9.4416,  ...,  -8.0414,  -8.3697,  -7.7104],\n",
      "         [-15.7526, -15.7268, -15.6716,  ..., -13.0981, -13.6872, -15.3081],\n",
      "         [-16.4689, -16.3558, -16.5029,  ..., -12.9810, -14.9521, -14.2455],\n",
      "         [-13.3109, -13.3634, -13.3491,  ..., -10.7415, -10.9095, -12.1695]]])\n",
      "relu_logits torch.Size([1, 4, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "log_relu_logits torch.Size([1, 4, 30522]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "attention_mask torch.Size([1, 4]) tensor([[1, 1, 1, 1]])\n",
      "attention_mask_unsqueezed torch.Size([1, 4, 1])\n",
      "logits_x_attention_mask torch.Size([1, 4, 30522])\n",
      "max_scores_by_tokens torch.Size([1, 30522])\n",
      "max_scores_by_tokens_squeezed torch.Size([30522])\n",
      "max_scores_by_tokens torch.Size([18, 1]) tensor([2009])\n",
      "cols [2009, 2486, 2552, 2693, 2801, 2895, 2929, 3125, 3147, 3247, 3537, 3574, 3795, 4023, 4368, 4633, 4785, 4808]\n",
      "weights [0.3333798348903656, 0.32605502009391785, 1.2158560752868652, 0.06287287920713425, 0.0504080131649971, 2.592545986175537, 1.7319773435592651, 0.4778487980365753, 1.3254261016845703, 0.6432759165763855, 0.06443876773118973, 0.3477742075920105, 7.60526381782256e-05, 0.32700344920158386, 0.34587082266807556, 1.782724142074585, 2.345621347427368, 0.6117227673530579]\n",
      "dict_items dict_items([('it', 0.3334), ('force', 0.3261), ('act', 1.2159), ('move', 0.0629), ('idea', 0.0504), ('action', 2.5925), ('movement', 1.732), ('goal', 0.4778), ('cold', 1.3254), ('decision', 0.6433), ('democratic', 0.0644), ('meaning', 0.3478), ('global', 0.0001), ('activity', 0.327), ('sport', 0.3459), ('weather', 1.7827), ('climate', 2.3456), ('violence', 0.6117)])\n",
      "sorted_sparse_dict_tokens [('action', 2.5925), ('climate', 2.3456), ('weather', 1.7827), ('movement', 1.732), ('cold', 1.3254), ('act', 1.2159), ('decision', 0.6433), ('violence', 0.6117), ('goal', 0.4778), ('meaning', 0.3478), ('sport', 0.3459), ('it', 0.3334), ('activity', 0.327), ('force', 0.3261), ('democratic', 0.0644), ('move', 0.0629), ('idea', 0.0504), ('global', 0.0001)]\n"
     ]
    }
   ],
   "source": [
    "# 検索語的なもの\n",
    "target = \"Climate action\" # 気候行動\n",
    "target_vector = sparce_encoder.encode(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: Climate action\n",
      "→ vec: {'action': 2.5925, 'climate': 2.3456, 'weather': 1.7827, 'movement': 1.732, 'cold': 1.3254, 'act': 1.2159, 'decision': 0.6433, 'violence': 0.6117, 'goal': 0.4778, 'meaning': 0.3478, 'sport': 0.3459, 'it': 0.3334, 'activity': 0.327, 'force': 0.3261, 'democratic': 0.0644, 'move': 0.0629, 'idea': 0.0504, 'global': 0.0001}\n",
      "8.21236882 Environmental conservation efforts are increasing to combat climate change.\n",
      "1.72356134 Global market trends indicate a shift towards renewable energy sources.\n",
      "0.7166878 Artificial intelligence is revolutionizing the way businesses operate.\n",
      "0.25009236 Educational reforms are essential for future workforce development.\n",
      "0.16637855999999998 Innovative technologies are transforming the healthcare industry.\n"
     ]
    }
   ],
   "source": [
    "print(f\"target: {target}\")\n",
    "print(f\"→ vec: {target_vector}\")\n",
    "sorted_scores = sorted(zip(texts, sparse_vectors), key=lambda x: get_score(x[1], target_vector), reverse=True)\n",
    "for text, vec in sorted_scores:\n",
    "  score = get_score(vec, target_vector)\n",
    "  print(f\"{score} {text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
