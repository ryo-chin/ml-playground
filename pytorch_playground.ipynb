{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([3, 1, 1, 2])\n",
      "tensor([[[[-0.9105,  1.5759]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9233, -0.9312]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1988,  0.2080]]]])\n",
      "x_squeezed torch.Size([3, 2])\n",
      "tensor([[-0.9105,  1.5759],\n",
      "        [ 1.9233, -0.9312],\n",
      "        [ 0.1988,  0.2080]])\n",
      "x_unsqueezed torch.Size([1, 3, 1, 1, 2])\n",
      "tensor([[[[[-0.9105,  1.5759]]],\n",
      "\n",
      "\n",
      "         [[[ 1.9233, -0.9312]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1988,  0.2080]]]]])\n",
      "tensor([[[[-0.9105,  1.5759]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1988,  0.2080]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 形状が(3, 1, 1, 2)のテンソルを作成\n",
    "x = torch.randn(3, 1, 1, 2)\n",
    "\n",
    "print('x', x.shape)\n",
    "print(x)\n",
    "\n",
    "# squeeze: 要素数が1の次元を削除\n",
    "x_squeezed = x.squeeze()\n",
    "print('x_squeezed', x_squeezed.shape)\n",
    "print(x_squeezed)\n",
    "\n",
    "# unsqueeze: 指定した次元に要素数1の次元を追加\n",
    "x_unsqueezed = x.unsqueeze(0)\n",
    "print('x_unsqueezed', x_unsqueezed.shape)\n",
    "print(x_unsqueezed)\n",
    "\n",
    "# テンソルに対してindexの配列渡して、そのindexの要素を取得\n",
    "idx = [0, 2]\n",
    "print(x[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "a - b tensor([[-4, -4],\n",
      "        [-4, -4]])\n",
      "a * b tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "a @ b tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "torch.max(a) dim=0 torch.return_types.max(\n",
      "values=tensor([3, 4]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.max(a) dim=1 torch.return_types.max(\n",
      "values=tensor([2, 4]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.max(c) dim=0 torch.return_types.max(\n",
      "values=tensor([[0.0000, 0.0000, 0.6000, 0.9000, 0.8000],\n",
      "        [0.8000, 0.0000, 0.0000, 0.7000, 0.0000]]),\n",
      "indices=tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]))\n",
      "col_max torch.Size([5]) tensor([0.8000, 0.0000, 0.6000, 0.9000, 0.8000])\n",
      "torch.max(c, dim=1).values.nonzero() torch.Size([4]) tensor([0, 2, 3, 4])\n",
      "col_max[nonzero_cols] tensor([0.8000, 0.6000, 0.9000, 0.8000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "    [1, 2], \n",
    "    [3, 4]])\n",
    "b = torch.tensor([\n",
    "    [5, 6], \n",
    "    [7, 8]])\n",
    "\n",
    "# テンソルの和\n",
    "print('a + b', a + b)\n",
    "# テンソルの差\n",
    "print('a - b', a - b)\n",
    "\n",
    "# テンソル要素感の積\n",
    "print('a * b', a * b)\n",
    "\n",
    "# テンソル同士の積\n",
    "print('a @ b', a @ b)\n",
    "\n",
    "# テンソルの要素の最大値\n",
    "# 列方向の最大値\n",
    "print('torch.max(a) dim=0', torch.max(a, dim=0))\n",
    "# 行方向の最大値\n",
    "print('torch.max(a) dim=1', torch.max(a, dim=1))\n",
    "\n",
    "# 3次元テンソルのmax\n",
    "c = torch.tensor([\n",
    "    [\n",
    "        [0, 0, 0.6, 0.9, 0.8], \n",
    "        [0.8, 0, 0, 0.7, 0]\n",
    "    ]])\n",
    "# 1次元目（バッチ数）の最大値. ただし、要素数が1つなのでそのまま値が返るかんじ\n",
    "print('torch.max(c) dim=0', torch.max(c, dim=0))\n",
    "# 2次元目（列方向）の最大値\n",
    "col_max = torch.max(c, dim=1).values.squeeze()\n",
    "print('col_max', col_max.shape, col_max)\n",
    "\n",
    "# nonzero: 非ゼロ要素のインデックスを取得\n",
    "nonzero_cols = col_max.nonzero().squeeze()\n",
    "print('torch.max(c, dim=1).values.nonzero()', nonzero_cols.shape, nonzero_cols)\n",
    "\n",
    "# 非ゼロ要素のインデックスで値を取り直す\n",
    "print('col_max[nonzero_cols]', col_max[nonzero_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array.shape=torch.Size([2, 3, 4])\n",
      "array.argmax(axis=0)=\n",
      "tensor([[0, 0, 1, 1],\n",
      "        [0, 1, 0, 0],\n",
      "        [1, 0, 1, 1]])\n",
      "array.argmax(axis=1)=\n",
      "tensor([[0, 2, 1, 1],\n",
      "        [2, 1, 0, 2]])\n",
      "array.argmax(axis=2)=\n",
      "tensor([[1, 1, 1],\n",
      "        [2, 1, 0]])\n",
      "tensor(9)\n",
      "tensor([[1, 1, 1],\n",
      "        [2, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "# argmaxの使い方\n",
    "# 下記の3次元配列を使う\n",
    "array = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [10, 20, 5, 3], \n",
    "            [4, 30, 6, 9], \n",
    "            [3, 80, 1, 2]\n",
    "        ],\n",
    "        [\n",
    "            [5, 10, 20, 8],\n",
    "            [3, 80, 1, 2],\n",
    "            [30, 20, 10, 9],\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "print(f\"array.shape={array.shape}\") # (2, 3, 4)の3次元配列\n",
    "\n",
    "# 3次元配列に対してaxisを指定する場合、\n",
    "# axis=0のとき、1次元目の要素内の同じ行の要素の中で最大値のインデックスを返す\n",
    "print(f\"array.argmax(axis=0)=\\n{array.argmax(axis=0)}\")\n",
    "# axis=1のとき、2次元目の行の要素の中で最大値のインデックスを返す\n",
    "print(f\"array.argmax(axis=1)=\\n{array.argmax(axis=1)}\")\n",
    "# axis=2のとき、3次元目の配列の要素の中で最大値のインデックスを返す\n",
    "print(f\"array.argmax(axis=2)=\\n{array.argmax(axis=2)}\")\n",
    "\n",
    "# axis=Noneの場合、1次元に変換して最大値のインデックスを返す\n",
    "print(array.argmax())\n",
    "# -1の場合、最後の次元(3次元ならaxis=2）に対して最大値のインデックスを返す\n",
    "print(array.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk.values=\n",
      "tensor([80, 30, 20, 10,  9])\n",
      "topk.indices=\n",
      "tensor([9, 5, 1, 0, 7])\n"
     ]
    }
   ],
   "source": [
    "# topkの使い方\n",
    "# 下記の1次元配列を使う\n",
    "array = torch.tensor([10, 20, 5, 3, 4, 30, 6, 9, 3, 80, 1, 2])\n",
    "\n",
    "# valuesとindicesを並び替えたうえで取得できる\n",
    "topk = array.topk(5)\n",
    "print(f\"topk.values=\\n{topk.values}\")\n",
    "print(f\"topk.indices=\\n{topk.indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ax=tensor([ 5, 11])\n",
      "eigenvalues, eigenvectors=((3.0, 2.0), [[1, -1.0], [1, -2.0]])\n",
      "eigenvalue=(2.9999990463256836+0j), eigenvector=tensor([-0.7071-0.j,  0.7071+0.j])\n",
      "eigenvalue=(2.000000476837158+0j), eigenvector=tensor([-0.4472+0.j,  0.8944+0.j])\n"
     ]
    }
   ],
   "source": [
    "# 線形変換の例\n",
    "# A = [[1, 2], [3, 4]], x = [1, 2]\n",
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "x = torch.tensor([1, 2])\n",
    "Ax = torch.matmul(A, x)\n",
    "print(f\"Ax={Ax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues, eigenvectors=((3.0, 2.0), [[1, -1.0], [1, -2.0]])\n",
      "eigenvalue=(2.9999990463256836+0j), eigenvector=tensor([-0.7071-0.j,  0.7071+0.j])\n",
      "eigenvalue=(2.000000476837158+0j), eigenvector=tensor([-0.4472+0.j,  0.8944+0.j])\n"
     ]
    }
   ],
   "source": [
    "# 固有ベクトル\n",
    "# 行列 A = [[4, 1], [-2, 1]] の固有ベクトルを求める\n",
    "# 固有値と固有ベクトルを求めるための手動計算\n",
    "def find_eigenvalues(matrix):\n",
    "    # 固有値は2次方程式 λ^2 - 5λ + 6 = 0 の解として計算される\n",
    "    a = 1\n",
    "    b = -5\n",
    "    c = 6\n",
    "    # 2次方程式の解\n",
    "    discriminant = b**2 - 4*a*c\n",
    "    lambda1 = (-b + discriminant**0.5) / (2*a)\n",
    "    lambda2 = (-b - discriminant**0.5) / (2*a)\n",
    "    return lambda1, lambda2\n",
    "\n",
    "def find_eigenvector(matrix, eigenvalue):\n",
    "    # 固有値を用いて固有ベクトルを求める\n",
    "    # Ax = λx -> (A - λI)x = 0 となるxを見つける\n",
    "    # 行列 (A - λI) を作成\n",
    "    modified_matrix = [[matrix[0][0] - eigenvalue, matrix[0][1]], \n",
    "                       [matrix[1][0], matrix[1][1] - eigenvalue]]\n",
    "    # この例では x = 1 を設定し y を解く\n",
    "    x = 1\n",
    "    y = -modified_matrix[0][0] * x / modified_matrix[0][1]\n",
    "    return [x, y]\n",
    "\n",
    "# 行列 A の定義\n",
    "A = [[4, 1], [-2, 1]]\n",
    "# 固有値を求める\n",
    "eigenvalues = find_eigenvalues(A)\n",
    "# 固有ベクトルを求める\n",
    "eigenvectors = [find_eigenvector(A, ev) for ev in eigenvalues]\n",
    "\n",
    "print(f\"eigenvalues, eigenvectors={eigenvalues, eigenvectors}\")\n",
    "\n",
    "\n",
    "# 以下はpytorchを使った計算\n",
    "# 計算式は、A * v = λ * v ここで、vは固有ベクトル、λは固有値\n",
    "# 固有ベクトルは、A - λI の行列のnull spaceを求めることで求めることができる ここで、Iは単位行列\n",
    "A = torch.tensor([[4, 1], [-2, 1]], dtype=torch.complex64)  # Convert A to complex data type\n",
    "# 以下でpytorchを使わずに求めてみる\n",
    "# 固有値を求める\n",
    "\n",
    "# complex dataとは、実数部と虚数部を持つデータ型\n",
    "# 固有ベクトルを求める\n",
    "eigenvalues, eigenvectors = torch.linalg.eig(A)\n",
    "# 固有値 eignevalues[i] に対して、固有ベクトル eigenvectors[:, i] が対応する\n",
    "for i in range(len(eigenvalues)):\n",
    "    print(f\"eigenvalue={eigenvalues[i]}, eigenvector={eigenvectors[:, i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
