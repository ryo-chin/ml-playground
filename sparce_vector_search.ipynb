{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./venv/lib/python3.12/site-packages (4.40.1)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./venv/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./venv/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.12/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryohei.yamamoto/projects/ml-playground/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SparseEncoder:\n",
    "    def __init__(self, model_id=\"naver/splade_v2_max\"):\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self._model = AutoModelForMaskedLM.from_pretrained(model_id)\n",
    "        self._model.eval()\n",
    "        # extract the ID position to text token mappings\n",
    "        self._idx2token = {\n",
    "            idx: token for token, idx in self._tokenizer.get_vocab().items()\n",
    "            }\n",
    "\n",
    "    def encode(self, text):\n",
    "        tokens = self._tokenizer([text], return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            output = self._model(**tokens)\n",
    "\n",
    "        vec = torch.max(\n",
    "            torch.log(1 + torch.relu(output.logits)) * tokens.attention_mask.unsqueeze(-1),\n",
    "            dim=1)[0].squeeze()\n",
    "\n",
    "        # extract non-zero positions\n",
    "        cols = vec.nonzero().squeeze().cpu().tolist()\n",
    "        # extract the non-zero values\n",
    "        weights = vec[cols].cpu().tolist()\n",
    "        # use to create a dictionary of token ID to weight\n",
    "        sparse_dict = dict(zip(cols, weights))\n",
    "        # map token IDs to human-readable tokens\n",
    "        sparse_dict_tokens = {\n",
    "            self._idx2token[idx]: round(weight, 4) for idx, weight in zip(cols, weights)\n",
    "        }\n",
    "        # sort so we can see most relevant tokens first\n",
    "        sparse_dict_tokens = {\n",
    "            k: v for k, v in sorted(\n",
    "                sparse_dict_tokens.items(),\n",
    "                key=lambda item: item[1],\n",
    "                reverse=True\n",
    "            )\n",
    "        }\n",
    "        return sparse_dict_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparce_encoder = SparseEncoder()\n",
    "text =  \"Programmed cell death (PCD) is the regulated death of cells within an organism\"\n",
    "sparce_vector = sparce_encoder.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pc': 2.5905,\n",
       " 'death': 2.4068,\n",
       " 'cell': 2.0662,\n",
       " 'programmed': 2.0624,\n",
       " '##d': 1.9653,\n",
       " 'organism': 1.6084,\n",
       " 'regulated': 1.4702,\n",
       " 'die': 1.4701,\n",
       " 'meaning': 1.4017,\n",
       " 'computer': 1.2484,\n",
       " 'regulation': 1.242,\n",
       " 'set': 1.1262,\n",
       " 'regulate': 0.809,\n",
       " 'cells': 0.7754,\n",
       " 'code': 0.6977,\n",
       " 'organisms': 0.6679,\n",
       " 'kill': 0.6577,\n",
       " 'controlled': 0.5733,\n",
       " 'within': 0.5619,\n",
       " 'master': 0.4954,\n",
       " 'radio': 0.4952,\n",
       " 'bacteria': 0.4649,\n",
       " 'goal': 0.4209,\n",
       " 'is': 0.3682,\n",
       " 'result': 0.3376,\n",
       " 'end': 0.3282,\n",
       " 'determined': 0.255,\n",
       " 'monitor': 0.2354,\n",
       " 'transfer': 0.2328,\n",
       " 'process': 0.1818,\n",
       " 'penalty': 0.1534,\n",
       " 'fear': 0.1488,\n",
       " 'gene': 0.112,\n",
       " 'cause': 0.1096,\n",
       " 'pd': 0.0834,\n",
       " 'happen': 0.0163}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparce_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.21236882 Environmental conservation efforts are increasing to combat climate change.\n",
      "1.72356134 Global market trends indicate a shift towards renewable energy sources.\n",
      "0.7166878 Artificial intelligence is revolutionizing the way businesses operate.\n",
      "0.25009236 Educational reforms are essential for future workforce development.\n",
      "0.16637855999999998 Innovative technologies are transforming the healthcare industry.\n"
     ]
    }
   ],
   "source": [
    "# 2つのベクトルのスコア計算（類似単語が多いとスコアが高くなる）\n",
    "def get_score(vec1, vec2):\n",
    "  score = 0.0\n",
    "  for k,v in vec1.items():\n",
    "    if k in vec2:\n",
    "      score += v * vec2.get(k)\n",
    "  return score\n",
    "\n",
    "# 検索対象の文書的なもの\n",
    "texts = [\n",
    "    \"Global market trends indicate a shift towards renewable energy sources.\",\n",
    "    # グローバル市場の動向は、再生可能エネルギー源へのシフトを示しています。\n",
    "    \"Innovative technologies are transforming the healthcare industry.\",\n",
    "    # 革新的な技術がヘルスケア産業を変革しています。\n",
    "    \"Educational reforms are essential for future workforce development.\",\n",
    "    # 教育改革は将来の労働力開発に不可欠です。\n",
    "    \"Environmental conservation efforts are increasing to combat climate change.\",\n",
    "    # 気候変動と戦うために、環境保全の努力が増加しています。\n",
    "    \"Artificial intelligence is revolutionizing the way businesses operate.\"\n",
    "    # 人工知能はビジネスの運営方法を革命的に変えています。\n",
    "]\n",
    "\n",
    "sparce_encoder = SparseEncoder()\n",
    "sparse_vectors = [sparce_encoder.encode(t) for t in texts]\n",
    "\n",
    "# 検索語的なもの\n",
    "target = \"Climate action\" # 気候行動\n",
    "target_vector = sparce_encoder.encode(target)\n",
    "\n",
    "sorted_scores = sorted(zip(texts, sparse_vectors), key=lambda x: get_score(x[1], target_vector), reverse=True)\n",
    "for text, vec in sorted_scores:\n",
    "  score = get_score(vec, target_vector)\n",
    "  print(f\"{score} {text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
